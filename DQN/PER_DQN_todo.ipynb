{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from utils.replaybuffer import PrioritizedBuffer\n",
    "from model import DQN\n",
    "from utils.AI_Interface import *\n",
    "from utils.reward import *\n",
    "from utils.action_transform import action_transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb35324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, learning_rate=3e-4, gamma=0.99, buffer_size=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.replay_buffer = PrioritizedBuffer(buffer_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = DQN(obs_shape=428,                 \n",
    "                         fStickLat_shape=21, fStickLon_shape=21,\n",
    "                 fThrottle_shape=11, fRudder_shape=21,\n",
    "                 eMainTaskMode=2, eEleScanLine_shape=2,\n",
    "                 eAziScanRange=3, WeaponLaunch=2).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state, eps=0.05):\n",
    "        state = torch.FloatTensor(state).float().unsqueeze(0).to(self.device)\n",
    "        qvals = self.model.forward(state) #list[tensor]\n",
    "        \n",
    "        #这里还需要获得每一种动作的离散化后的列表，将argmax后得到的index放入列表中采样\n",
    "        #假设叫做action_list\n",
    "        action_list = []\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1)),1)\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1)),1)\n",
    "        action_list.append(np.round(np.arange(0, 1.1, 0.1)),1)\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1)),1)\n",
    "        action_list.append(np.round(np.array([30,60,120])),1)\n",
    "        action_list.append(np.round(np.array([2,4])),1)\n",
    "        action_list.append(np.round(np.array([0,1])),1)\n",
    "        action_list.append(np.round(np.array([0,1])),1)\n",
    "        \n",
    "        action = []\n",
    "        if(np.random.randn() < eps):\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][random.randint(0, len(action_list[i])-1)])\n",
    "        else:\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][np.argmax(qvals[i].cpu().detach().numpy())])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def compute_td(self, batch_size):\n",
    "        transitions, idxs, IS_weights = self.replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = transitions\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "        IS_weights = torch.FloatTensor(IS_weights).to(self.device)\n",
    "        done_mask = torch.abs(dones - 1).reshape(batch_size,1)\n",
    "\n",
    "        q = self.model.forward(states)\n",
    "        for i in range(len(q)):\n",
    "            if i == 0:\n",
    "                curr_Q = q[i].gather(1, actions[:,i].unsqueeze(1))\n",
    "            else:\n",
    "                curr_Q = torch.cat([curr_Q,q[i].gather(1, actions[:,i].unsqueeze(1))],1)\n",
    "\n",
    "        q_ = self.model.forward(next_states)\n",
    "        for i in range(len(q_)):\n",
    "            if i == 0:\n",
    "                max_next_Q = torch.max(q_[i], 1)[0].unsqueeze(1)\n",
    "            else:\n",
    "                max_next_Q = torch.cat([max_next_Q, torch.max(q_[i], 1)[0].unsqueeze(1)], 1)\n",
    "        expected_Q = rewards + self.gamma * max_next_Q * done_mask\n",
    "\n",
    "        # 第一种 分开输出\n",
    "#         td_errors = []\n",
    "#         for i in range(len(q_)):\n",
    "#             td_errors.append(torch.pow(curr_Q[i] - expected_Q[i], 2) * IS_weights)\n",
    "        \n",
    "        #第二种 加起来\n",
    "        td_errors = 0\n",
    "        for i in range(len(q_)):\n",
    "            td_errors += torch.pow(curr_Q[i] - expected_Q[i], 2) * IS_weights\n",
    "            \n",
    "#         td_errors = torch.pow(curr_Q - expected_Q, 2) * IS_weights\n",
    "        \n",
    "        return td_errors, idxs\n",
    "\n",
    "    def update(self, batch_size):\n",
    "        td_errors, idxs = self.compute_td(batch_size)\n",
    "        \n",
    "#          分开版\n",
    "#         self.optimizer.zero_grad()\n",
    "#         for i in range(len(td_errors)):\n",
    "#             td_errors[i].mean().backward()\n",
    "#         self.optimizer.step()\n",
    "        \n",
    "#         加和版\n",
    "        td_errors_mean = td_errors.mean()\n",
    "        self.optimizer.zero_grad()\n",
    "        td_errors_mean.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # update priorities\n",
    "        for idx, td_error in zip(idxs, td_errors.cpu().detach().numpy()):\n",
    "            self.replay_buffer.update_priority(idx, td_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a330622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangchenghao/TX_airplane/DQN/utils/replaybuffer.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  self.tree[parent] += change\n"
     ]
    }
   ],
   "source": [
    "# 暂时没有交互，只有从buffer中采样，学习\n",
    "# 把data用循环存入buffer中\n",
    "\n",
    "agent = DQNAgent()\n",
    "    \n",
    "data = pd.read_csv('../data',header=None)\n",
    "\n",
    "i = 2\n",
    "while i < (len(data)-3):\n",
    "    # 假设我们是红色飞机，蓝色飞机的动作默认不知道\n",
    "    # 把红蓝的input做成state，动作是红色的output\n",
    "    # 注意：428-609是空空导弹数据，不能用作state\n",
    "    state = data.iloc[i][:428].tolist()\n",
    "    \n",
    "    next_state = data.iloc[i+2][:428].tolist()\n",
    "    \n",
    "    action = data.iloc[i][609:].tolist()\n",
    "    action = action_transform(action)\n",
    "    \n",
    "    # 为了方便做奖励，将所有变量都归类\n",
    "    # 需要当前input，当前output，上一步input\n",
    "    input_r_cur, output_r_cur = getStateAndAction(data.iloc[i])\n",
    "    input_b_cur, output_b_cur = getStateAndAction(data.iloc[i+1])\n",
    "    input_r_pre, _ = getStateAndAction(data.iloc[i-2])\n",
    "    input_b_pre, _ = getStateAndAction(data.iloc[i-1])\n",
    "    reward = getReward(input_r_pre, input_b_pre,\n",
    "             output_r_cur, output_b_cur,\n",
    "             input_r_cur, input_b_cur)\n",
    "    \n",
    "    # 终止flag\n",
    "    # 不知道时间单位，暂时没有考虑终止条件2\n",
    "    if ((input_r_cur.m_AircraftBasicInfo.m_bAlive == 0 or \n",
    "        input_r_cur.m_AircraftBasicInfo.m_fFuel <= 0 or\n",
    "        input_r_cur.m_AircraftMoveInfo.m_dSelfAlt <= 0) or\n",
    "        (input_b_cur.m_AircraftBasicInfo.m_bAlive == 0 or \n",
    "        input_b_cur.m_AircraftBasicInfo.m_fFuel <= 0 or\n",
    "        input_b_cur.m_AircraftMoveInfo.m_dSelfAlt <= 0)):\n",
    "        for i in range(len(input_r_cur.m_AAMDataSet.m_AAMData)):\n",
    "            if (input_r_cur.m_AAMDataSet.m_AAMData[i].m_eAAMState != 0) or \\\n",
    "            (input_b_cur.m_AAMDataSet.m_AAMData[i].m_eAAMState != 0):\n",
    "                done = 0\n",
    "            else:\n",
    "                done = 1\n",
    "    else:\n",
    "        done = 0\n",
    "    \n",
    "    agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    i = i + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b3f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangchenghao/TX_airplane/DQN/utils/replaybuffer.py:134: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  a = segment * i\n",
      "/home/huangchenghao/TX_airplane/DQN/utils/replaybuffer.py:143: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  IS_weight = (self.sum_tree.total() * prob) ** (-self.beta)\n",
      "/opt/conda/lib/python3.7/random.py:374: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return a + (b-a) * self.random()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16616/233383007.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16616/52569189.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mtd_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#          分开版\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16616/52569189.py\u001b[0m in \u001b[0;36mcompute_td\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIS_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/huangchenghao/TX_airplane/DQN/utils/replaybuffer.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mstate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0maction_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "MAX_EPISODES = 1000\n",
    "MAX_STEPS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "agent.update(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1f4b3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3742748864.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_19984/3742748864.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \"C:\\Users\\Mr. Huang\\Desktop\\Airplane\\TX_Distribution\\Deploy\\BVR\\AIPilots\\Intelligame\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(agent,\n",
    "                  (state),\n",
    "                  \"F:\\TX_Distribution\\Deploy\\BVR\\AIPilots\\Intelligame\\model.onnx\", \n",
    "                   export_params=True,        # 是否保存训练好的参数在网络中\n",
    "                   opset_version=10,          # ONNX算子版本\n",
    "                   do_constant_folding=True,  # 是否不保存常数输出（优化选项）\n",
    "                   input_names = ['input0'],   \n",
    "                   output_names = ['output0', 'output1', 'output2', 'output3', 'output4', 'output5', 'output6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721f290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
