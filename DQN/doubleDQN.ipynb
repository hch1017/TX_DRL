{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from utils.replaybuffer import BasicBuffer\n",
    "from model import DQN\n",
    "from utils.AI_Interface import *\n",
    "from utils.reward import *\n",
    "from utils.action_transform import action_transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb35324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, learning_rate=3e-4, gamma=0.99, buffer_size=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.replay_buffer = BasicBuffer(max_size=buffer_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model1 = DQN(obs_shape=428,                 \n",
    "                         fStickLat_shape=21, fStickLon_shape=21,\n",
    "                 fThrottle_shape=11, fRudder_shape=21,\n",
    "                 eMainTaskMode=2, eEleScanLine_shape=2,\n",
    "                 eAziScanRange=3, WeaponLaunch=2).to(self.device)\n",
    "        \n",
    "        self.model2 = DQN(obs_shape=428,                 \n",
    "                         fStickLat_shape=21, fStickLon_shape=21,\n",
    "                 fThrottle_shape=11, fRudder_shape=21,\n",
    "                 eMainTaskMode=2, eEleScanLine_shape=2,\n",
    "                 eAziScanRange=3, WeaponLaunch=2).to(self.device)\n",
    "\n",
    "        self.optimizer1 = torch.optim.Adam(self.model1.parameters())\n",
    "        self.optimizer2 = torch.optim.Adam(self.model2.parameters())\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state, eps=0.20):\n",
    "        state = torch.FloatTensor(state).float().unsqueeze(0).to(self.device)\n",
    "        qvals = self.model.forward(state) #list[tensor]\n",
    "        \n",
    "        #这里还需要获得每一种动作的离散化后的列表，将argmax后得到的index放入列表中采样\n",
    "        #假设叫做action_list\n",
    "        action_list = []\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1),1).tolist())\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1),1).tolist())\n",
    "        action_list.append(np.round(np.arange(0, 1.1, 0.1),1).tolist())\n",
    "        action_list.append(np.round(np.arange(-1.0, 1.1, 0.1),1).tolist())\n",
    "        action_list.append(np.array([0,1]).tolist())\n",
    "        action_list.append(np.array([2,4]).tolist())\n",
    "        action_list.append(np.array([30,60,120]).tolist())\n",
    "        action_list.append(np.array([0,1]).tolist())\n",
    "        \n",
    "        action = []\n",
    "        if(np.random.randn() < eps):\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][random.randint(0, len(action_list[i])-1)])\n",
    "        else:\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][np.argmax(qvals[i].cpu().detach().numpy())])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def compute_loss(self, batch):\n",
    "        states, actions, rewards, next_states, dones = batch\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones)\n",
    "\n",
    "        q1 = self.model1.forward(states)\n",
    "        q2 = self.model2.forward(states)\n",
    "        for i in range(len(q1)):\n",
    "            if i == 0:\n",
    "                curr_Q1 = q1[i].gather(1, actions[:,i].unsqueeze(1))\n",
    "                curr_Q2 = q2[i].gather(1, actions[:,i].unsqueeze(1))\n",
    "            else:\n",
    "                curr_Q1 = torch.cat([curr_Q1, q1[i].gather(1, actions[:,i].unsqueeze(1))],1)\n",
    "                curr_Q2 = torch.cat([curr_Q2, q2[i].gather(1, actions[:,i].unsqueeze(1))],1)\n",
    "        \n",
    "        q1_ = self.model1.forward(next_states)\n",
    "        q2_ = self.model2.forward(next_states)\n",
    "        for i in range(len(q1_)):\n",
    "            if i == 0:\n",
    "                max_next_Q1 = torch.max(q1_[i], 1)[0].unsqueeze(1)\n",
    "                max_next_Q2 = torch.max(q2_[i], 1)[0].unsqueeze(1)\n",
    "                max_next_Q = torch.min(max_next_Q1,max_next_Q2)\n",
    "            else:\n",
    "                max_next_Q1 = torch.max(q1_[i], 1)[0].unsqueeze(1)\n",
    "                max_next_Q2 = torch.max(q2_[i], 1)[0].unsqueeze(1)\n",
    "                max_next_Q = torch.cat([max_next_Q, torch.min(max_next_Q1,max_next_Q2)], 1)\n",
    "        expected_Q = rewards + self.gamma * max_next_Q        \n",
    "\n",
    "        # 第一种 分开输出\n",
    "#         loss1 = []\n",
    "#         loss2 = []\n",
    "#         for i in range(len(q1_)):\n",
    "#             loss1.append(self.MSE_loss(curr_Q1[0], expected_Q[0]))\n",
    "#             loss2.append(self.MSE_loss(curr_Q2[0], expected_Q[0]))\n",
    "        \n",
    "        #第二种 加起来\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        for i in range(len(q1_)):\n",
    "            loss1 += self.MSE_loss(curr_Q1[0], expected_Q[0])\n",
    "            loss2 += self.MSE_loss(curr_Q2[0], expected_Q[0])\n",
    "        \n",
    "        return loss1, loss2\n",
    "\n",
    "    def update(self, batch_size):\n",
    "        batch = self.replay_buffer.sample(batch_size)\n",
    "        loss1, loss2 = self.compute_loss(batch)\n",
    "        \n",
    "#          分开版\n",
    "#         self.optimizer1.zero_grad()\n",
    "#         self.optimizer2.zero_grad()\n",
    "        \n",
    "#         for i in range(len(loss1)):\n",
    "#             loss1[i].backward()\n",
    "#         for i in range(len(loss2)):\n",
    "#             loss2[i].backward()\n",
    "            \n",
    "#         self.optimizer1.step()\n",
    "#         self.optimizer2.step()\n",
    "        \n",
    "#         加和版        \n",
    "        self.optimizer1.zero_grad()\n",
    "        self.optimizer2.zero_grad()\n",
    "        loss1.backward(retain_graph=True)\n",
    "        loss2.backward(retain_graph=True)\n",
    "        self.optimizer1.step()\n",
    "        self.optimizer2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b930557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 暂时没有交互，只有从buffer中采样，学习\n",
    "# 把data用循环存入buffer中\n",
    "\n",
    "agent = DQNAgent()\n",
    "    \n",
    "data = pd.read_csv('../data',header=None)\n",
    "\n",
    "i = 2\n",
    "while i < (len(data)-3):\n",
    "    # 假设我们是红色飞机，蓝色飞机的动作默认不知道\n",
    "    # 把红蓝的input做成state，动作是红色的output\n",
    "    # 注意：428-609是空空导弹数据，不能用作state\n",
    "    state = data.iloc[i][:428].tolist()\n",
    "    \n",
    "    next_state = data.iloc[i+2][:428].tolist()\n",
    "    \n",
    "    action = data.iloc[i][609:].tolist()\n",
    "    action = action_transform(action)\n",
    "    \n",
    "    # 为了方便做奖励，将所有变量都归类\n",
    "    # 需要当前input，当前output，上一步input\n",
    "    input_r_cur, output_r_cur = getStateAndAction(data.iloc[i])\n",
    "    input_b_cur, output_b_cur = getStateAndAction(data.iloc[i+1])\n",
    "    input_r_pre, _ = getStateAndAction(data.iloc[i-2])\n",
    "    input_b_pre, _ = getStateAndAction(data.iloc[i-1])\n",
    "    reward = getReward(input_r_pre, input_b_pre,\n",
    "             output_r_cur, output_b_cur,\n",
    "             input_r_cur, input_b_cur)\n",
    "    \n",
    "    # 终止flag\n",
    "    # 不知道时间单位，暂时没有考虑终止条件2\n",
    "    if ((input_r_cur.m_AircraftBasicInfo.m_bAlive == 0 or \n",
    "        input_r_cur.m_AircraftBasicInfo.m_fFuel <= 0 or\n",
    "        input_r_cur.m_AircraftMoveInfo.m_dSelfAlt <= 0) or\n",
    "        (input_b_cur.m_AircraftBasicInfo.m_bAlive == 0 or \n",
    "        input_b_cur.m_AircraftBasicInfo.m_fFuel <= 0 or\n",
    "        input_b_cur.m_AircraftMoveInfo.m_dSelfAlt <= 0)):\n",
    "        for i in range(len(input_r_cur.m_AAMDataSet.m_AAMData)):\n",
    "            if (input_r_cur.m_AAMDataSet.m_AAMData[i].m_eAAMState != 0) or \\\n",
    "            (input_b_cur.m_AAMDataSet.m_AAMData[i].m_eAAMState != 0):\n",
    "                done = 0\n",
    "            else:\n",
    "                done = 1\n",
    "    else:\n",
    "        done = 0\n",
    "    \n",
    "    agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    i = i + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223a7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 1000\n",
    "MAX_STEPS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for _ in range(MAX_EPISODES):\n",
    "    agent.update(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ff1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.model1,'checkpoint/DoubleDQN1.pt')\n",
    "torch.save(agent.model2,'checkpoint/DoubleDQN2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1f4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(agent.model1.cpu(),\n",
    "                  (torch.randn(428)),\n",
    "                  \"checkpoint/double_dqn1.onnx\", \n",
    "                   export_params=True,        # 是否保存训练好的参数在网络中\n",
    "                   opset_version=10,          # ONNX算子版本\n",
    "                   do_constant_folding=True,  # 是否不保存常数输出（优化选项）\n",
    "                   input_names = ['input0'],   \n",
    "                   output_names = ['fStickLat_shape', 'fStickLon_shape',\n",
    "                                     'fThrottle_shape', 'fRudder_shape',\n",
    "                                     'eMainTaskMode', 'eEleScanLine_shape',\n",
    "                                     'eAziScanRange', 'WeaponLaunch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71bf91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(agent.model2.cpu(),\n",
    "                  (torch.randn(428)),\n",
    "                  \"checkpoint/double_dqn2.onnx\", \n",
    "                   export_params=True,        # 是否保存训练好的参数在网络中\n",
    "                   opset_version=10,          # ONNX算子版本\n",
    "                   do_constant_folding=True,  # 是否不保存常数输出（优化选项）\n",
    "                   input_names = ['input0'],   \n",
    "                   output_names = ['fStickLat_shape', 'fStickLon_shape',\n",
    "                                     'fThrottle_shape', 'fRudder_shape',\n",
    "                                     'eMainTaskMode', 'eEleScanLine_shape',\n",
    "                                     'eAziScanRange', 'WeaponLaunch'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
