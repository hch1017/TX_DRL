{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from utils.replaybuffer import PrioritizedBuffer\n",
    "from model import DuelingDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, learning_rate=3e-4, gamma=0.99, buffer_size=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.replay_buffer = PrioritizedBuffer(buffer_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model1 = DuelingDQN(obs_shape=, ).to(self.device)\n",
    "        self.model2 = DuelingDQN(obs_shape=, ).to(self.device)\n",
    "\n",
    "        self.optimizer1 = torch.optim.Adam(self.model1.parameters())\n",
    "        self.optimizer2 = torch.optim.Adam(self.model2.parameters())\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "        \n",
    "    def get_action(self, state, eps=0.05):\n",
    "        state = torch.FloatTensor(state).float().unsqueeze(0).to(self.device)\n",
    "        qvals = self.model.forward(state) #list[tensor]\n",
    "        action = []\n",
    "        #这里还需要获得每一种动作的离散化后的列表，将argmax后得到的index放入列表中采样\n",
    "        #假设叫做action_list\n",
    "        if(np.random.randn() < eps):\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][random.randint(0, len(action_list[i])-1)])\n",
    "        else:\n",
    "            for i in range(len(qvals)):\n",
    "                action.append(action_list[i][np.argmax(qvals[i].cpu().detach().numpy())])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def compute_td(self, batch_size):\n",
    "        transitions, idxs, IS_weights = self.replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = transitions\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "        IS_weights = torch.FloatTensor(IS_weights).to(self.device)\n",
    "        done_mask = torch.abs(dones - 1).reshape(batch_size,1)\n",
    "\n",
    "        actions = actions.view(actions.size(0), 1)\n",
    "        dones = dones.view(dones.size(0), 1)\n",
    "        \n",
    "        curr_Q1 = self.model1.forward(states).gather(1, actions)\n",
    "        curr_Q2 = self.model2.forward(states).gather(1, actions)\n",
    "        \n",
    "        next_Q1 = self.model1.forward(next_states)\n",
    "        next_Q2 = self.model2.forward(next_states)\n",
    "        next_Q = torch.min(\n",
    "            torch.max(self.model1.forward(next_states),1)[0]\n",
    "            torch.max(self.model2.forward(next_states),1)[0]\n",
    "        )\n",
    "        next_Q = next_Q.view(next_Q.size(0), 1)\n",
    "        expected_Q = rewards.squeeze(1) + self.gamma * max_next_Q * done_mask\n",
    "        \n",
    "        td_errors1 = torch.pow(curr_Q1 - expected_Q, 2) * IS_weights\n",
    "        td_errors2 = torch.pow(curr_Q2 - expected_Q, 2) * IS_weights\n",
    "        \n",
    "        return td_errors1, td_errors2, idxs\n",
    "\n",
    "    def update(self, batch_size):\n",
    "        td_errors1, td_errors2, idxs = self.compute_td(batch_size)\n",
    "\n",
    "        # update model\n",
    "        td_errors_mean1 = td_errors1.mean()\n",
    "        td_errors_mean2 = td_errors2.mean()\n",
    "        \n",
    "        self.optimizer1.zero_grad()\n",
    "        td_errors_mean1.backward()\n",
    "        self.optimizer1.step()\n",
    "        \n",
    "        self.optimizer2.zero_grad()\n",
    "        td_errors_mean2.backward()\n",
    "        self.optimizer2.step()\n",
    "\n",
    "        # update priorities\n",
    "        for idx, td_error in zip(idxs, td_errors1.cpu().detach().numpy()):\n",
    "            self.replay_buffer.update_priority(idx, td_error1)\n",
    "        for idx, td_error in zip(idxs, td_errors1.cpu().detach().numpy()):\n",
    "            self.replay_buffer.update_priority(idx, td_error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af045dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 1000\n",
    "MAX_STEPS = 500\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 暂时没有交互，只有从buffer中采样，学习\n",
    "# 把data用循环存入buffer中\n",
    "agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "for _ in range(MAX_EPISODES):\n",
    "    agent.update(BATCH_SIZE)\n",
    "\n",
    "torch.save(agent.model,'checkpoint/DQN.pt')\n",
    "agent.model.load_state_dict(torch.load('checkpoint/DQN.pt'))\n",
    "    \n",
    "# episode_rewards = []\n",
    "\n",
    "# for episode in range(MAX_EPISODES):\n",
    "#     state = env.reset()\n",
    "#     episode_reward = 0\n",
    "\n",
    "#     for step in range(max_steps):\n",
    "#         action = agent.get_action(state)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "#         agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "#         episode_reward += reward\n",
    "\n",
    "#         if len(agent.replay_buffer) > BATCH_SIZE:\n",
    "#             agent.update(BATCH_SIZE)   \n",
    "\n",
    "#         if done or step == MAX_STEPS-1:\n",
    "#             episode_rewards.append(episode_reward)\n",
    "#             print(\"Episode \" + str(episode) + \": \" + str(episode_reward))\n",
    "#             break\n",
    "\n",
    "#         state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1f4b3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3742748864.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_19984/3742748864.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \"C:\\Users\\Mr. Huang\\Desktop\\Airplane\\TX_Distribution\\Deploy\\BVR\\AIPilots\\Intelligame\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(agent,\n",
    "                  (state),\n",
    "                  \"F:\\TX_Distribution\\Deploy\\BVR\\AIPilots\\Intelligame\\model.onnx\", \n",
    "                   export_params=True,        # 是否保存训练好的参数在网络中\n",
    "                   opset_version=10,          # ONNX算子版本\n",
    "                   do_constant_folding=True,  # 是否不保存常数输出（优化选项）\n",
    "                   input_names = ['input0'],   \n",
    "                   output_names = ['output0', 'output1', 'output2', 'output3', 'output4', 'output5', 'output6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5da8d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 616 fields in line 8543, saw 617\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19984/3845649885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 616 fields in line 8543, saw 617\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('F:/TX_Distribution/Deploy/BVR/save_observation/data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721f290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
